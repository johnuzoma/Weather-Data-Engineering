{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d055d60e-d94b-4baf-9a33-e7815bc42ab7",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Notebook by John Uzoma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463732b6-61ba-43fe-a821-8d3a5a3c6b78",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Load silver table into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52204d75-c555-4372-83bd-cbba09a55b46",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Read silver tables as dataframes\n",
    "textForecast = spark.read.table(\"lakehouse.dublintextforecast_silver\")\n",
    "weatherForecast = spark.read.table(\"lakehouse.dublinweatherforecast_silver\")\n",
    "weatherWarning = spark.read.table(\"lakehouse.dublinweatherwarning_silver\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d947d182-84ac-4a25-9323-86a90dbc8440",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Optimize delta table writes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0f005d-a4ef-4f82-9fa8-73f9b1767611",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Enable V-Order\n",
    "spark.conf.set(\"spark.sql.parquet.vorder.enabled\", \"true\")\n",
    "    \n",
    "# Enable automatic Delta optimized write\n",
    "spark.conf.set(\"spark.microsoft.delta.optimizeWrite.enabled\", \"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f061beb-76fe-4bf8-9a2b-fc480d06368b",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Generate fact dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5702db5-8f4e-4e9b-8a2d-569c2d9430e5",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# List of all columns except \"Issued\" from textForecast and weatherWarning\n",
    "textForecast_columns_to_select = [col for col in textForecast.columns if col != \"Issued\"]\n",
    "weatherWarning_columns_to_select = [col for col in weatherWarning.columns if col != \"Issued\"]\n",
    "\n",
    "# Perform the join and select the required columns to generate fact dataframe\n",
    "fact_df = weatherForecast.join(textForecast, weatherForecast[\"Date\"] == textForecast[\"Issued\"], \"left\") \\\n",
    "        .join(weatherWarning, weatherForecast[\"Date\"] == weatherWarning[\"Issued\"], \"left\") \\\n",
    "        .select(\n",
    "            weatherForecast[\"*\"], \n",
    "            *[textForecast[col] for col in textForecast_columns_to_select], \n",
    "            *[weatherWarning[col] for col in weatherWarning_columns_to_select]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeda3575-9aaa-4010-bc8c-a3811e5b7a09",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Define schema for gold fact table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1429bb61-9158-4daa-9738-6649e1e6d597",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import TimestampType, StringType, FloatType, DateType\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "DeltaTable.createIfNotExists(spark) \\\n",
    "    .tableName(\"lakehouse.fact_dublinweather_gold\") \\\n",
    "    .addColumn(\"Date\", DateType()) \\\n",
    "    .addColumn(\"Time\", StringType()) \\\n",
    "    .addColumn(\"Temperature_celsius\", FloatType()) \\\n",
    "    .addColumn(\"PreviousTemperature\", FloatType()) \\\n",
    "    .addColumn(\"WindDirection\", StringType()) \\\n",
    "    .addColumn(\"WindSpeed_mps\", FloatType()) \\\n",
    "    .addColumn(\"PreviousWindSpeed\", FloatType()) \\\n",
    "    .addColumn(\"WindGust_mps\", FloatType()) \\\n",
    "    .addColumn(\"PreviousWindGust\", FloatType()) \\\n",
    "    .addColumn(\"GlobalRadiation_wpsqm\", FloatType()) \\\n",
    "    .addColumn(\"PreviousGlobalRadiation\", FloatType()) \\\n",
    "    .addColumn(\"Humidity_percent\", FloatType()) \\\n",
    "    .addColumn(\"PreviousHumidity\", FloatType()) \\\n",
    "    .addColumn(\"Pressure_hPa\", FloatType()) \\\n",
    "    .addColumn(\"PreviousPressure\", FloatType()) \\\n",
    "    .addColumn(\"Cloudiness_percent\", FloatType()) \\\n",
    "    .addColumn(\"PreviousCloudiness\", FloatType()) \\\n",
    "    .addColumn(\"DewpointTemperature_celsius\", FloatType()) \\\n",
    "    .addColumn(\"PreviousDewpointTemperature\", FloatType()) \\\n",
    "    .addColumn(\"ForecastFrom\", TimestampType()) \\\n",
    "    .addColumn(\"ForecastTo\", TimestampType()) \\\n",
    "    .addColumn(\"Precipitation_mm\", FloatType()) \\\n",
    "    .addColumn(\"PreviousPrecipitation\", FloatType()) \\\n",
    "    .addColumn(\"WeatherType\", StringType()) \\\n",
    "    .addColumn(\"TextForecastIssueTime\", StringType()) \\\n",
    "    .addColumn(\"Today\", StringType()) \\\n",
    "    .addColumn(\"Tonight\", StringType()) \\\n",
    "    .addColumn(\"Tomorrow\", StringType()) \\\n",
    "    .addColumn(\"Outlook\", StringType()) \\\n",
    "    .addColumn(\"Level\", StringType()) \\\n",
    "    .addColumn(\"Severity\", StringType()) \\\n",
    "    .addColumn(\"Certainty\", StringType()) \\\n",
    "    .addColumn(\"WarningIssueTime\", StringType()) \\\n",
    "    .addColumn(\"Updated\", TimestampType()) \\\n",
    "    .addColumn(\"Onset\", TimestampType()) \\\n",
    "    .addColumn(\"Expiry\", TimestampType()) \\\n",
    "    .addColumn(\"Headline\", StringType()) \\\n",
    "    .addColumn(\"Description\", StringType()) \\\n",
    "    .addColumn(\"Status\", StringType()) \\\n",
    "    .execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c7ff7f-5178-40b8-94c0-2a44699e65d8",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Write fact dataframe to gold table (upsert operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0ba929-d7f8-4e25-8b92-e278e52efcfa",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Update existing records and insert new ones based on a condition defined by the columns: Date and Time\n",
    "    \n",
    "deltaTable = DeltaTable.forPath(spark, 'Tables/fact_dublinweather_gold')    \n",
    "\n",
    "dfUpdates = fact_df\n",
    "    \n",
    "deltaTable.alias('gold') \\\n",
    "  .merge(\n",
    "    dfUpdates.alias('updates'),\n",
    "    'gold.Date = updates.Date and gold.Time = updates.Time'\n",
    "  ) \\\n",
    "   .whenMatchedUpdate(set =\n",
    "    {\n",
    "      \"Temperature_celsius\": \"updates.Temperature_celsius\",\n",
    "      \"PreviousTemperature\": \"updates.PreviousTemperature\",\n",
    "      \"WindDirection\": \"updates.WindDirection\",\n",
    "      \"WindSpeed_mps\": \"updates.WindSpeed_mps\",\n",
    "      \"PreviousWindSpeed\": \"updates.PreviousWindSpeed\",\n",
    "      \"WindGust_mps\": \"updates.WindGust_mps\",\n",
    "      \"PreviousWindGust\": \"updates.PreviousWindGust\",\n",
    "      \"GlobalRadiation_wpsqm\": \"updates.GlobalRadiation_wpsqm\",\n",
    "      \"PreviousGlobalRadiation\": \"updates.PreviousGlobalRadiation\",\n",
    "      \"Humidity_percent\": \"updates.Humidity_percent\",\n",
    "      \"PreviousHumidity\": \"updates.PreviousHumidity\",\n",
    "      \"Pressure_hPa\": \"updates.Pressure_hPa\",\n",
    "      \"PreviousPressure\": \"updates.PreviousPressure\",\n",
    "      \"Cloudiness_percent\": \"updates.Cloudiness_percent\",\n",
    "      \"PreviousCloudiness\": \"updates.PreviousCloudiness\",\n",
    "      \"DewpointTemperature_celsius\": \"updates.DewpointTemperature_celsius\",\n",
    "      \"PreviousDewpointTemperature\": \"updates.PreviousDewpointTemperature\",\n",
    "      \"ForecastFrom\": \"updates.ForecastFrom\",\n",
    "      \"ForecastTo\": \"updates.ForecastTo\",\n",
    "      \"Precipitation_mm\": \"updates.Precipitation_mm\",\n",
    "      \"PreviousPrecipitation\": \"updates.PreviousPrecipitation\",\n",
    "      \"WeatherType\": \"updates.WeatherType\",\n",
    "      \"TextForecastIssueTime\": \"updates.TextForecastIssueTime\",\n",
    "      \"Today\": \"updates.Today\",\n",
    "      \"Tonight\": \"updates.Tonight\",\n",
    "      \"Tomorrow\": \"updates.Tomorrow\",\n",
    "      \"Outlook\": \"updates.Outlook\",\n",
    "      \"Level\": \"updates.Level\",\n",
    "      \"Severity\": \"updates.Severity\",\n",
    "      \"Certainty\": \"updates.Certainty\",\n",
    "      \"WarningIssueTime\": \"updates.WarningIssueTime\",\n",
    "      \"Updated\": \"updates.Updated\",\n",
    "      \"Onset\": \"updates.Onset\",\n",
    "      \"Expiry\": \"updates.Expiry\",\n",
    "      \"Headline\": \"updates.Headline\",\n",
    "      \"Description\": \"updates.Description\",\n",
    "      \"Status\": \"updates.Status\"\n",
    "    }\n",
    "  ) \\\n",
    " .whenNotMatchedInsert(values =\n",
    "    {\n",
    "      \"Date\": \"updates.Date\",\n",
    "      \"Time\": \"updates.Time\",\n",
    "      \"Temperature_celsius\": \"updates.Temperature_celsius\",\n",
    "      \"PreviousTemperature\": \"updates.PreviousTemperature\",\n",
    "      \"WindDirection\": \"updates.WindDirection\",\n",
    "      \"WindSpeed_mps\": \"updates.WindSpeed_mps\",\n",
    "      \"PreviousWindSpeed\": \"updates.PreviousWindSpeed\",\n",
    "      \"WindGust_mps\": \"updates.WindGust_mps\",\n",
    "      \"PreviousWindGust\": \"updates.PreviousWindGust\",\n",
    "      \"GlobalRadiation_wpsqm\": \"updates.GlobalRadiation_wpsqm\",\n",
    "      \"PreviousGlobalRadiation\": \"updates.PreviousGlobalRadiation\",\n",
    "      \"Humidity_percent\": \"updates.Humidity_percent\",\n",
    "      \"PreviousHumidity\": \"updates.PreviousHumidity\",\n",
    "      \"Pressure_hPa\": \"updates.Pressure_hPa\",\n",
    "      \"PreviousPressure\": \"updates.PreviousPressure\",\n",
    "      \"Cloudiness_percent\": \"updates.Cloudiness_percent\",\n",
    "      \"PreviousCloudiness\": \"updates.PreviousCloudiness\",\n",
    "      \"DewpointTemperature_celsius\": \"updates.DewpointTemperature_celsius\",\n",
    "      \"PreviousDewpointTemperature\": \"updates.PreviousDewpointTemperature\",\n",
    "      \"ForecastFrom\": \"updates.ForecastFrom\",\n",
    "      \"ForecastTo\": \"updates.ForecastTo\",\n",
    "      \"Precipitation_mm\": \"updates.Precipitation_mm\",\n",
    "      \"PreviousPrecipitation\": \"updates.PreviousPrecipitation\",\n",
    "      \"WeatherType\": \"updates.WeatherType\",\n",
    "      \"TextForecastIssueTime\": \"updates.TextForecastIssueTime\",\n",
    "      \"Today\": \"updates.Today\",\n",
    "      \"Tonight\": \"updates.Tonight\",\n",
    "      \"Tomorrow\": \"updates.Tomorrow\",\n",
    "      \"Outlook\": \"updates.Outlook\",\n",
    "      \"Level\": \"updates.Level\",\n",
    "      \"Severity\": \"updates.Severity\",\n",
    "      \"Certainty\": \"updates.Certainty\",\n",
    "      \"WarningIssueTime\": \"updates.WarningIssueTime\",\n",
    "      \"Updated\": \"updates.Updated\",\n",
    "      \"Onset\": \"updates.Onset\",\n",
    "      \"Expiry\": \"updates.Expiry\",\n",
    "      \"Headline\": \"updates.Headline\",\n",
    "      \"Description\": \"updates.Description\",\n",
    "      \"Status\": \"updates.Status\"\n",
    "    }\n",
    "  ) \\\n",
    "  .execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78656bd4-bae6-42d1-9b78-ef7af94c33b9",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Generate date dimension dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9209e381-82e9-4dbd-bef6-e50a88c69f2e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import dayofmonth, year, date_format\n",
    "\n",
    "# Extract date, day, month and year values from fact_df\n",
    "date_dim_df = fact_df.select(\n",
    "        (\"Date\"), \\\n",
    "        dayofmonth(\"Date\").alias(\"Day\"), \\\n",
    "        date_format(\"Date\", \"MMM\").substr(1, 3).alias(\"Month\"), \\\n",
    "        year(\"Date\").alias(\"Year\")\n",
    "    ).orderBy(\"Date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb111cf0-8cea-40c6-9cad-1557795193e5",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Drop duplicates in Date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7764176-8f16-4f2a-a2a3-617204080309",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "date_dim_df = date_dim_df.dropDuplicates([\"Date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d203d26e-c1ae-444a-b268-6b63e666429a",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Define schema for date dimension table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b5cf3f-aa1d-418f-a7a5-dce8c980c7d8",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "# Define the schema for the dim_date_gold table\n",
    "DeltaTable.createIfNotExists(spark) \\\n",
    "    .tableName(\"lakehouse.dim_date_gold\") \\\n",
    "    .addColumn(\"Date\", DateType()) \\\n",
    "    .addColumn(\"Day\", IntegerType()) \\\n",
    "    .addColumn(\"Month\", StringType()) \\\n",
    "    .addColumn(\"Year\", IntegerType()) \\\n",
    "    .execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58094e2d-0b06-4ed0-aa4f-6129be31cd21",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Write date dimension dataframe to gold table (upsert operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f6048f-cd96-4685-a76b-c8a94ea8b2dc",
   "metadata": {
    "advisor": {
     "adviceMetadata": "{\"artifactId\":\"b8783adf-287c-461b-8810-84db04c7c2e3\",\"activityId\":\"5653086f-7283-4c23-aad3-c591222e20c8\",\"applicationId\":\"application_1723192262733_0001\",\"jobGroupId\":\"11\",\"advices\":{\"info\":1}}"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Update existing records and insert new ones based on a condition defined by the column: Date\n",
    "    \n",
    "deltaTable = DeltaTable.forPath(spark, 'Tables/dim_date_gold')    \n",
    "\n",
    "dfUpdates = date_dim_df\n",
    "    \n",
    "deltaTable.alias('gold') \\\n",
    "  .merge(\n",
    "    dfUpdates.alias('updates'),\n",
    "    'gold.Date = updates.Date'\n",
    "  ) \\\n",
    "   .whenMatchedUpdate(set =\n",
    "    {\n",
    "      \"Day\": \"updates.Day\",\n",
    "      \"Month\": \"updates.Month\",\n",
    "      \"Year\": \"updates.Year\"\n",
    "    }\n",
    "  ) \\\n",
    " .whenNotMatchedInsert(values =\n",
    "    {\n",
    "      \"Date\": \"updates.Date\",\n",
    "      \"Day\": \"updates.Day\",\n",
    "      \"Month\": \"updates.Month\",\n",
    "      \"Year\": \"updates.Year\"\n",
    "    }\n",
    "  ) \\\n",
    "  .execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5f24cc-0f6d-4c0c-8a30-62b16caade63",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Generate weather type dimension dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb5fbdd-054c-4766-9a80-ebf4a54f9c71",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import dayofmonth, year, date_format, when, lower\n",
    "\n",
    "# Extract WeatherType from fact dataframe and drop duplicates\n",
    "weather_type_dim_df = fact_df.select((\"WeatherType\")).dropDuplicates([\"WeatherType\"])\n",
    "\n",
    "# Create column Flag to have value 1 when WeatherType contains rain or drizzle (case3 insensitive), otherwise 0\n",
    "weather_type_dim_df = weather_type_dim_df.withColumn(\n",
    "    \"Flag\", \n",
    "    when(\n",
    "        lower(weather_type_dim_df.WeatherType).contains(\"rain\") | lower(weather_type_dim_df.WeatherType).contains(\"drizzle\"),\n",
    "        1\n",
    "    ).otherwise(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2a5b1a-d259-4daf-9647-2dd85960e253",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Define schema for weather type dimension table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12943f9-068b-495d-ba8f-62f36d97c136",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import ByteType\n",
    "\n",
    "DeltaTable.createIfNotExists(spark) \\\n",
    "    .tableName(\"lakehouse.dim_weathertype_gold\") \\\n",
    "    .addColumn(\"WeatherType\", StringType()) \\\n",
    "    .addColumn(\"Flag\", ByteType()) \\\n",
    "    .execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fc5002-53f0-46ea-b6e6-70a7c3aa65a5",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Write weather type dimension dataframe to gold table (overwrite operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94af058-efbc-40c4-bacc-0ae4280be96b",
   "metadata": {
    "advisor": {
     "adviceMetadata": "{\"artifactId\":\"b8783adf-287c-461b-8810-84db04c7c2e3\",\"activityId\":\"5653086f-7283-4c23-aad3-c591222e20c8\",\"applicationId\":\"application_1723192262733_0001\",\"jobGroupId\":\"18\",\"advices\":{\"info\":1}}"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "weather_type_dim_df.write.format(\"delta\").mode(\"overwrite\").option(\"mergeSchema\", \"true\").save(\"Tables/dim_weathertype_gold\")"
   ]
  }
 ],
 "metadata": {
  "dependencies": {
   "lakehouse": {
    "default_lakehouse": "06a9b01e-67c7-4d49-b134-528745660f6b",
    "default_lakehouse_name": "lakehouse",
    "default_lakehouse_workspace_id": "6c2dfd82-79ca-43af-b447-84d78a797dd3"
   }
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "language": "Python",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default"
  },
  "synapse_widget": {
   "state": {},
   "version": "0.1"
  },
  "widgets": {}
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
