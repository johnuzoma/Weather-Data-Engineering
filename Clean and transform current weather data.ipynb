{"cells":[{"cell_type":"markdown","source":["###### *Notebook developed by John Uzoma*"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"9b316591-ba9c-499b-a4c6-0e708151063a"},{"cell_type":"markdown","source":["## Load from JSON to pySpark dataframe\n","###### Since I intend to include this notebook as part of a data pipeline that will run automatically on a schedule, I will create a function to make the file path dynamic, so I don't read the same file at each run."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"c3d777c8-1fb9-4f5d-85dc-34ca713c2ed7"},{"cell_type":"code","source":["from datetime import datetime\n","\n","def read_in_todays_data():\n","    '''\n","    Function that dynamically retrieves the filepath based on today's date\n","    Returns a dataframe of today's date\n","    '''\n","    dt_now = datetime.now()\n","    # dt_now = 2024-03-25 19:58:49.789007\n","\n","    dt_string = dt_now.strftime(\"%Y/%m/%d\")\n","    # dt_string = 2024/03/25\n","\n","    dynamic_file_path = f\"Files/{dt_string}/CurrentWeather.json\"\n","    # dynamic_file_path = \"Files/2024/03/25/CurrentWeather.json\"\n","\n","    try:\n","        # Load JSON data into a dataframe\n","        df = spark.read.json(dynamic_file_path)\n","        return df\n","    except Exception as err:\n","        print(err)\n","\n","df = read_in_todays_data()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":null,"state":"waiting","livy_statement_state":null,"queued_time":"2024-03-27T15:58:37.9044741Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":null,"parent_msg_id":"66cd973c-cad1-44f1-8eaf-8afe71322c7e"},"text/plain":"StatementMeta(, , , Waiting, )"},"metadata":{}}],"execution_count":3,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"collapsed":false},"id":"078b1b46-8ce6-46fb-ab9e-52ecaa99b799"},{"cell_type":"markdown","source":["## Data cleaning (with code refactoring using functions)"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"bd54f79b-e614-499d-9c5a-e923d25743ed"},{"cell_type":"code","source":["from pyspark.sql.functions import col, to_timestamp, round, lit\n","\n","# function to convert date column from unix to datetime\n","def convert_unix_to_datetime(unix_datetime_col):\n","    return to_timestamp(unix_datetime_col)\n","\n","# function to convert temperature column from kelvin to celsius and fahrenheit, rounded to 2 decimal places\n","def temperature_conversion(kelvin_col, to_unit):\n","    if to_unit == 'celsius':\n","        return round(kelvin_col - 273.15, 2)\n","    elif to_unit == 'fah':\n","        return round((col(\"main.temp\") * 9/5) - 459.67, 2)\n","\n","# use df.select to flatten the structure of our nested JSON\n","flattened_df = df.select(\n","    convert_unix_to_datetime(col(\"dt\")).alias(\"datetime\"),\n","    col(\"main.temp\").alias(\"temperature_kelvin\"),\n","    temperature_conversion(col(\"main.temp\"), to_unit=\"celsius\").alias(\"temperature_celsius\"),\n","    temperature_conversion(col(\"main.temp\"), to_unit=\"fah\").alias(\"temperature_fahrenheit\")\n",")\n","\n","# create a new column 'Type' with value 'Historic'\n","flattened_df = flattened_df.withColumn(\"Type\", lit(\"Historic\"))\n","\n","flattened_df.printSchema()\n","display(flattened_df)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":null,"state":"waiting","livy_statement_state":null,"queued_time":"2024-03-27T16:01:25.2472568Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":null,"parent_msg_id":"280cf118-4ebb-45ef-8806-2b465e52f0e0"},"text/plain":"StatementMeta(, , , Waiting, )"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["root\n |-- datetime: timestamp (nullable = true)\n |-- temperature_kelvin: double (nullable = true)\n |-- temperature_celsius: double (nullable = true)\n |-- temperature_fahrenheit: double (nullable = true)\n |-- Type: string (nullable = false)\n\n"]},{"output_type":"display_data","data":{"application/vnd.synapse.widget-view+json":{"widget_id":"a1967d6e-130e-4fee-8706-1cbd86b930b5","widget_type":"Synapse.DataFrame"},"text/plain":"SynapseWidget(Synapse.DataFrame, a1967d6e-130e-4fee-8706-1cbd86b930b5)"},"metadata":{}}],"execution_count":4,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"collapsed":false},"id":"5dd08142-654f-42a5-ab44-3122fdd343c3"},{"cell_type":"markdown","source":["## Load the dataframe into a Lakehouse table\n","###### I used the append method to load the row of data into my Lakehouse table, while preserving existing data."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"645da1fa-9d70-46fa-8956-2b98291b85af"},{"cell_type":"code","source":["flattened_df.write.format(\"delta\").mode(\"append\").save(\"Tables/historic_weather_data\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":null,"state":"waiting","livy_statement_state":null,"queued_time":"2024-03-27T16:02:06.4089746Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":null,"parent_msg_id":"0aa682d2-f2da-48cd-aba5-b9286643b608"},"text/plain":"StatementMeta(, , , Waiting, )"},"metadata":{}}],"execution_count":4,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"8b627e17-2bd8-4bcb-a5e3-2dfba246205f"}],"metadata":{"language_info":{"name":"python"},"kernel_info":{"name":"synapse_pyspark"},"microsoft":{"language":"python"},"widgets":{},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{"a1967d6e-130e-4fee-8706-1cbd86b930b5":{"type":"Synapse.DataFrame","sync_state":{"table":{"rows":[{"0":"2024-03-27 09:00:04","1":"279.53","2":"6.38","3":"43.48","4":"Historic","index":1}],"schema":[{"key":"0","name":"datetime","type":"timestamp"},{"key":"1","name":"temperature_kelvin","type":"double"},{"key":"2","name":"temperature_celsius","type":"double"},{"key":"3","name":"temperature_fahrenheit","type":"double"},{"key":"4","name":"Type","type":"string"}],"truncated":false},"isSummary":false,"language":"scala"},"persist_state":{"view":{"type":"details","tableOptions":{},"chartOptions":{"chartType":"bar","categoryFieldKeys":["4"],"seriesFieldKeys":["1"],"aggregationType":"sum","isStacked":false,"binsNumber":10,"wordFrequency":"-1"}}}}}},"spark_compute":{"compute_id":"/trident/default"},"dependencies":{"lakehouse":{"default_lakehouse":"07789afb-4a11-4254-8649-f6007d9f443e","known_lakehouses":[{"id":"07789afb-4a11-4254-8649-f6007d9f443e"}],"default_lakehouse_name":"weather_lakehouse","default_lakehouse_workspace_id":"1a2ce695-a6f3-4878-b98a-2bdd38702570"}}},"nbformat":4,"nbformat_minor":5}